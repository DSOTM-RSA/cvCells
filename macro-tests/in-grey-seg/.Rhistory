if ("package:h2o" %in% search()) detach("package:h2o", unload=TRUE)
if ("h2o" %in% rownames(installed.packages())) remove.packages("h2o")
install.packages("h2o", type = "source",
repos = "http://h2o-release.s3.amazonaws.com/h2o/rel-turing/6/R")
library(sparklyr)
library(sparklyr)
library(rsparkling)
library(dplyr)
sc <- spark_connect("local", version = "1.6.2")
mtcars_tbl <- copy_to(sc, mtcars, "mtcars", overwrite = TRUE)
partitions <- mtcars_tbl %>%
filter(hp >= 100) %>%
mutate(cyl8 = cyl == 8) %>%
sdf_partition(training = 0.5, test = 0.5, seed = 1099)
training <- as_h2o_frame(sc, partitions$training)
test <- as_h2o_frame(sc, partitions$test)
glm_model <- h2o.glm(x = c("wt", "cyl"),
y = "mpg",
training_frame = training,
lambda_search = TRUE)
print(glm_model)
library(ggplot2)
# compute predicted values on our test dataset
pred <- h2o.predict(glm_model, newdata = test)
# convert from H2O Frame to Spark DataFrame
predicted <- as_spark_dataframe(sc, pred)
# extract the true 'mpg' values from our test dataset
actual <- partitions$test %>%
select(mpg) %>%
collect() %>%
`[[`("mpg")
# produce a data.frame housing our predicted + actual 'mpg' values
data <- data.frame(
predicted = predicted,
actual    = actual
)
# a bug in data.frame does not set colnames properly; reset here
names(data) <- c("predicted", "actual")
# plot predicted vs. actual values
ggplot(data, aes(x = actual, y = predicted)) +
geom_abline(lty = "dashed", col = "red") +
geom_point() +
theme(plot.title = element_text(hjust = 0.5)) +
coord_fixed(ratio = 1) +
labs(
x = "Actual Fuel Consumption",
y = "Predicted Fuel Consumption",
title = "Predicted vs. Actual Fuel Consumption"
)
iris_tbl <- copy_to(sc, iris, "iris", overwrite = TRUE)
iris_tbl
iris_hf <- as_h2o_frame(sc, iris_tbl)
kmeans_model <- h2o.kmeans(training_frame = iris_hf,
x = 3:4,
k = 3,
seed = 1)
h2o.centroid_stats(kmeans_model)
pca_model <- h2o.prcomp(training_frame = iris_hf,
x = 1:4,
k = 4,
seed = 1)
print(pca_model)
y <- "Species"
x <- setdiff(names(iris_hf), y)
iris_hf[,y] <- as.factor(iris_hf[,y])
splits <- h2o.splitFrame(iris_hf, seed = 1)
rf_model <- h2o.randomForest(x = x,
y = y,
training_frame = splits[[1]],
validation_frame = splits[[2]],
nbins = 32,
max_depth = 5,
ntrees = 20,
seed = 1)
h2o.confusionMatrix(rf_model, valid = TRUE)
h2o.varimp_plot(rf_model)
gbm_model <- h2o.gbm(x = x,
y = y,
training_frame = splits[[1]],
validation_frame = splits[[2]],
ntrees = 20,
max_depth = 3,
learn_rate = 0.01,
col_sample_rate = 0.7,
seed = 1)
h2o.confusionMatrix(gbm_model, valid = TRUE)
path <- system.file("extdata", "prostate.csv", package = "h2o")
prostate_df <- spark_read_csv(sc, "prostate", path)
head(prostate_df)
prostate_hf <- as_h2o_frame(sc, prostate_df)
splits <- h2o.splitFrame(prostate_hf, seed = 1)
y <- "VOL"
x <- setdiff(names(prostate_hf), c("ID", y))
dl_fit <- h2o.deeplearning(x = x, y = y,
training_frame = splits[[1]],
epochs = 15,
activation = "Rectifier",
hidden = c(10, 5, 10),
input_dropout_ratio = 0.7)
h2o.performance(dl_fit, newdata = splits[[2]])
splits <- h2o.splitFrame(prostate_hf, seed = 1)
y <- "VOL"
#remove response and ID cols
x <- setdiff(names(prostate_hf), c("ID", y))
# GBM hyperparamters
gbm_params1 <- list(learn_rate = c(0.01, 0.1),
max_depth = c(3, 5, 9),
sample_rate = c(0.8, 1.0),
col_sample_rate = c(0.2, 0.5, 1.0))
# Train and validate a grid of GBMs
gbm_grid1 <- h2o.grid("gbm", x = x, y = y,
grid_id = "gbm_grid1",
training_frame = splits[[1]],
validation_frame = splits[[1]],
ntrees = 100,
seed = 1,
hyper_params = gbm_params1)
gbm_gridperf1 <- h2o.getGrid(grid_id = "gbm_grid1",
sort_by = "mse",
decreasing = FALSE)
print(gbm_gridperf1)
gbm_params2 <- list(learn_rate = seq(0.01, 0.1, 0.01),
max_depth = seq(2, 10, 1),
sample_rate = seq(0.5, 1.0, 0.1),
col_sample_rate = seq(0.1, 1.0, 0.1))
search_criteria2 <- list(strategy = "RandomDiscrete",
max_models = 150)
# Train and validate a grid of GBMs
gbm_grid2 <- h2o.grid("gbm", x = x, y = y,
grid_id = "gbm_grid2",
training_frame = splits[[1]],
validation_frame = splits[[2]],
ntrees = 100,
seed = 1,
hyper_params = gbm_params2,
search_criteria = search_criteria2)
gbm_gridperf2 <- h2o.getGrid(grid_id = "gbm_grid2",
sort_by = "mse",
decreasing = FALSE)
gbm_gridperf2@summary_table[1,]
install.packages("rbokeh")
library(sparklyr)
library(dplyr)
library(babynames)
library(ggplot2)
library(dygraphs)
library(rbokeh)
install.packages("dygraphs")
sc <- spark_connect(master = "local")
babynames_tbl <- copy_to(sc, babynames, "babynames")
applicants_tbl <- copy_to(sc, applicants, "applicants")
birthsYearly <- applicants_tbl %>% mutate(male = ifelse(sex=="M",n_all,0), female=ifelse(sex== "F",n_all,0))
birthsYearly <- applicants_tbl %>% mutate(male = ifelse(sex=="M",n_all,0), female=ifelse(sex== "F",n_all,0)) %>% group_by(year) %>% summarize(Male=sum(male)/ 1000000, Female = sum(female) / 1000000) %>% arrange(year) %>% collect
birthsYearly <- applicants_tbl %>% mutate(male = ifelse(sex=="M",n_all,0), female=ifelse(sex== "F",n_all,0)) %>% collect()
View(birthsYearly)
birthsYearly <- applicants_tbl %>% mutate(male = ifelse(sex=="M",n_all,0), female=ifelse(sex== "F",n_all,0)) %>% group_by(year) %>% summarize(Male=sum(male)/ 1000000, Female = sum(female) / 1000000) %>% arrange(year) %>% collect
View(birthsYearly)
birthsYearly %>%
dygraph(main = "Total US Births (SSN)", ylab = "Millions") %>%
dySeries("Female") %>%
dySeries("Male") %>%
dyOptions(stackedGraph = TRUE) %>%
dyRangeSelector(height = 20)
install.packages("dygraphs")
library(dygraphs)
birthsYearly %>%
dygraph(main = "Total US Births (SSN)", ylab = "Millions") %>%
dySeries("Female") %>%
dySeries("Male") %>%
dyOptions(stackedGraph = TRUE) %>%
dyRangeSelector(height = 20)
topNames_tbl <- babynames_tbl %>% filter(year >=1986) %>% group_by(name,sex) %>% summarize(count =as.numeric(sum(n)))
topNames_tbl <- babynames_tbl %>% filter(year >=1986) %>% group_by(name,sex) %>% summarize(count =as.numeric(sum(n))) %>% collect()
View(topNames_tbl)
View(birthsYearly)
topNames_tbl <- babynames_tbl %>%
filter(year >= 1986) %>%
group_by(name, sex) %>%
summarize(count = as.numeric(sum(n))) %>%
filter(count > 1000) %>%
select(name, sex) %>% collect()
View(topNames_tbl)
filteredNames_tbl <- babynames_tbl %>%
filter(year >= 1986) %>%
inner_join(topNames_tbl) %>% collect()
filteredNames_tbl <- babynames_tbl %>%
filter(year >= 1986) %>%
inner_join(topNames_tbl)
topNames_tbl <- babynames_tbl %>%
filter(year >= 1986) %>%
group_by(name, sex) %>%
summarize(count = as.numeric(sum(n))) %>%
filter(count > 1000) %>%
select(name, sex)
filteredNames_tbl <- babynames_tbl %>%
filter(year >= 1986) %>%
inner_join(topNames_tbl)
filteredNames_tbl <- babynames_tbl %>%
filter(year >= 1986) %>%
inner_join(topNames_tbl) %>% collect()
filteredNames_tbl <- babynames_tbl %>%
filter(year >= 1986) %>%
inner_join(topNames_tbl)
yearlyNames_tbl <- filteredNames_tbl %>%
group_by(year, name, sex) %>%
summarize(count = as.numeric(sum(n)))
sdf_register(yearlyNames_tbl, "yearlyNames")
topNames_tbl <- babynames_tbl %>%
filter(year >= 1986) %>%
group_by(name, sex) %>%
summarize(count = as.numeric(sum(n)))
topNames_tbl <- babynames_tbl %>%
filter(year >= 1986) %>%
group_by(name, sex) %>%
summarize(count = as.numeric(sum(n))) %>% collect()
View(topNames_tbl)
View(birthsYearly)
View(birthsYearly)
data("babynames")
data("babynames")
View(babynames)
res <-babynames %>% filter(name=="Mary")
View(res)
res <-babynames %>% filter(name=="Mary" | sex == "M")
View(res)
res <-babynames %>% filter(name=="Mary" , sex == "M")
View(res)
res <-babynames %>% filter(name=="Mary" , sex == "F")
View(res)
plot(res$year,res$prop)
plot(res$year,res$prop*100)
res <-babynames %>% filter(name=="Beyonce" , sex == "F")
plot(res$year,res$prop*100)
res <-babynames %>% filter(name=="Salvador" , sex == "M")
plot(res$year,res$prop*100)
res <-babynames %>% filter(name=="Daniel" , sex == "M")
plot(res$year,res$prop*100)
res <-babynames %>% filter(name=="George" , sex == "M")
plot(res$year,res$prop*100)
res <-babynames %>% filter(name=="John" , sex == "M")
plot(res$year,res$prop*100)
res <-babynames %>% filter(name=="Paul" , sex == "M")
plot(res$year,res$prop*100)
res <-babynames %>% filter(name=="Jennifer" , sex == "F")
plot(res$year,res$prop*100)
res <-babynames %>% filter(name=="Audrey" , sex == "F")
plot(res$year,res$prop*100)
res <-babynames %>% filter(name=="Marilyn" , sex == "F")
plot(res$year,res$prop*100)
res <-babynames %>% filter(name=="Elvis" , sex == "M")
plot(res$year,res$prop*100)
res <-babynames %>% filter(name=="Michael" , sex == "M")
plot(res$year,res$prop*100)
res <-babynames %>% filter(name=="Rupert" , sex == "M")
plot(res$year,res$prop*100)
res <-babynames %>% filter(name=="Gordon" , sex == "M")
plot(res$year,res$prop*100)
res <-babynames %>% filter(name=="Donald" , sex == "M")
plot(res$year,res$prop*100)
res <-babynames %>% filter(year >= 1980)
View(res)
res <-babynames %>% filter(year >= 1980) %>% group_by(name,sex) %>% summarize(count = sum(n)) %>% group_by(sex)
View(res)
res <-babynames %>% filter(year >= 1980) %>% group_by(name,sex) %>% summarize(count = sum(n)) %>% group_by(sex) %>% mutate(rank = min_rank(desc(count))) %>% filter(rank < 10) M %>% arrange(sex,rank)
res <-babynames %>% filter(year >= 1980) %>% group_by(name,sex) %>% summarize(count = sum(n)) %>% group_by(sex) %>% mutate(rank = min_rank(desc(count))) %>% filter(rank < 10) %>% arrange(sex,rank)
View(res)
res <-babynames %>% filter(year >= 1980) %>% group_by(name,sex) %>% summarize(count = sum(n)) %>% group_by(sex) %>% mutate(rank = min_rank(desc(count))) %>% filter(rank < 10) %>% arrange(sex,rank) %>% select(name,sex,rank)
View(res)
topNames1986Yearly <- babynames %>%
inner_join(select(res, sex, name))
View(topNames_tbl)
View(topNames1986Yearly)
ggplot(topNames1986Yearly, aes(year, count, color=name)) +
facet_grid(~sex) +
geom_line() +
ggtitle("Most Popular Names of 1986")
ggplot(topNames1986Yearly, aes(year, count, color=name)) +
facet_grid(~sex) +
geom_line() +
ggtitle("Most Popular Names of 1986")
ggplot(topNames1986Yearly, aes(year, n, color=name)) +
facet_grid(~sex) +
geom_line() +
ggtitle("Most Popular Names of 1986")
res <-babynames %>% filter(year >= 1980) %>% group_by(name,sex) %>% summarize(count = sum(n)) %>% group_by(sex) %>% mutate(rank = min_rank(desc(count))) %>% filter(rank < 4) %>% arrange(sex,rank) %>% select(name,sex,rank)
topNames1986Yearly <- babynames %>%
inner_join(select(res, sex, name))
ggplot(topNames1986Yearly, aes(year, n, color=name)) +
facet_grid(~sex) +
geom_line() +
ggtitle("Most Popular Names of 1986")
ggplot(topNames1986Yearly, aes(year, prop, color=name)) +
facet_grid(~sex) +
geom_line() +
ggtitle("Most Popular Names of 1986")
setwd("~/Research/cvCells/macro-tests")
setwd("~/Research/cvCells/macro-tests/in-grey-seg")
library(EBImage)
# species names here for individual dBase
sp.sec<-"all"
# basic book-keeping -- list all files
refs.all <-list.files(pattern = paste0("*-g-",sp.sec))
segs.all <-list.files(pattern = paste0("*-g-",sp.sec))
# for all samples in library
refs.all <-list.files(pattern = "*-g-")
segs.all <-list.files(pattern = "*-s-")
beg = 1
end = as.numeric(length(refs.all))
# short labels for meta-data
ref <-as.character(strsplit(refs.all,".tif"))
seg <-as.character(strsplit(segs.all,".tif"))
# main loop
for (i in beg:end){
# read and label segmented images
refs.array <-readImage(refs.all[i])
seg.array <-readImage(segs.all[i])
seg.labelled <-bwlabel(seg.array)
# contruct holders for feature-results
writer.1 <-paste0("shapes",i)
writer.2 <-paste0("textures",i)
# compute features
fts.shp <-computeFeatures(seg.labelled,refs.array)
fts.tex <-computeFeatures.haralick(seg.labelled,refs.array)
# assigning source file ids to rownames for book-keeping
rownames(fts.shp) <-rep(ref[i],dim(fts.shp)[1])
# use assign for each feature set
assign(writer.1,fts.shp)
assign(writer.2,fts.tex)
}
# concenate pieces into one matrix
rm(list=ls(pattern = "^fts"))
pieces.shp <-Filter(function(x) is(x, "matrix"),mget(ls(pattern = "^shapes")))
pieces.tex <-Filter(function(x) is(x, "matrix"), mget(ls(pattern= "^textures")))
# construct lists
data.shapes <-do.call(rbind,pieces.shp)
data.textures <-do.call(rbind,pieces.tex)
# trim data
crt <-which(data.shapes[,6]>=10000) # size criteria here
data.shapes.trim <-data.shapes[crt,] # apply to shape data
data.textures.trim <-data.textures[crt,] # apply for textures
# bind rows for full array of features
array.images <-cbind(data.shapes.trim,data.textures.trim)
# Part II - Data Export ----
# libs needed
library(stringr)
library(magrittr)
rm(list = ls(pattern = "^shapes"))
rm(list = ls(pattern = "^textures"))
# to DF - change name here!!
array.dfs <-as.data.frame(array.images)
# create a column of image-names
rNames <-rownames(array.dfs)
rNames.tag <-str_sub(rNames,-4)
array.dfs %<>% cbind(rNames.tag,.) # bind to array
save(array.dfs,file=paste0("array","-",sp.sec,".Rdata")) # export as .Rdata file
write.csv(array.dfs,file = paste0("array","-",sp.sec,".csv"),row.names = FALSE) # write out feature matrix to .csv
# Part III - Model Creation ----
# libs needed
library(FFTrees)
library(dplyr)
# load in data-sets
load("array-all.Rdata")
library(sparklyr)# Section A - Binary Classification
sp.0<-"iacu" # assign species 0
sp.1<-"ipat" # assign species 1
dat.bin <- array.dfs %>% filter(.,rNames.tag == sp.0 | rNames.tag == sp.1)
dat.bin$tagBinary <- 0
dat.bin$tagBinary[dat.bin$rNames.tag == sp.1] <-1
dat.bin.fft.mar <- FFTrees(formula = tagBinary~.,
data = dat.bin[,2:117],rank.method = "m") # use all features outside label
dat.bin.fft.mar
# plot tree
plot(dat.bin.fft.mar,
main = "Dino FFT",
decision.names = c(sp.0, sp.1))
# plotting some of parameters used
library(caret)
library(AppliedPredictiveModeling)
# featurePlot from caret
transparentTheme(trans = .9)
featurePlot(x = dat.bin[, 91:100],
y = dat.bin$rNames.tag,
plot = "density",
## Pass in options to xyplot() to
## make it prettier
scales = list(x = list(relation="free"),
y = list(relation="free")),
adjust = 1.5,
pch = "|",
layout = c(5, 2),auto.key = list(columns = 2))
# Section B - Multiclass: preProcessing in caret, models in Spark
library(caret)
load("array-all.Rdata")
# indentifying correlated parameters (i.e not for PLS)
feats <- array.dfs[-1]
descrCor <- cor(feats)
highlyCorDescr <- findCorrelation(descrCor, cutoff = .95)
filteredDescr <- feats[,-highlyCorDescr]
array-all-trim<-cbind(array.dfs[1],filteredDescr)
library(dplyr)
library(sparklyr)
# connect to instance
sc <- spark_connect(master = "local")
features_tbl <- spark_read_csv(sc, name = 'featLib', path = '~/Research/cvCells/macro-tests/in-grey-seg/array-all-trim.csv')
# fit linear model
partitions <- features_tbl %>%
sdf_partition(training = 0.75, test = 0.25, seed = 1099)
fit <- partitions$training %>%
ml_linear_regression(response = "x_0_s_area", features = c("x_0_s_perimeter", "x_0_m_majoraxis"))
summary(fit)
# kmeans test
kmeans_model <- features_tbl %>%
select(x_0_s_area, x_0_m_majoraxis) %>%
ml_kmeans(centers = 3)
print(kmeans_model)
# predict the associated class
predicted <- sdf_predict(kmeans_model, features_tbl) %>%
collect
table(predicted$rNames_tag, predicted$prediction)
library(ggplot2)
sdf_predict(kmeans_model) %>%
collect() %>%
ggplot(aes(x_0_s_area, x_0_m_majoraxis)) +
geom_point(aes(x_0_m_majoraxis, x_0_s_area, col = factor(prediction + 1)),
size = 2, alpha = 0.5) +
geom_point(data = kmeans_model$centers, aes(x_0_m_majoraxis, x_0_s_area),
col = scales::muted(c("red", "green", "blue")),
pch = 'x', size = 12) +
scale_color_discrete(name = "Predicted Cluster",
labels = paste("Cluster", 1:3)) +
labs(
x = "x_0_m_majoraxis",
y = "x_0_s_area",
title = "K-Means Clustering",
subtitle = "Use Spark.ML to predict cluster membership with this dataset."
)
# rf model
rf_model <- features_tbl %>%
ml_random_forest(rNames_tag ~ x_0_s_area + x_0_m_majoraxis, type = "classification")
rf_predict <- sdf_predict(rf_model, features_tbl) %>%
ft_string_indexer("rNames_tag", "rNames_idx") %>%
collect
# print the classification results
table(rf_predict$rNames_idx, rf_predict$prediction)
ft_string2idx <- features_tbl %>%
ft_string_indexer("rNames_tag", "rNames_idx") %>%
ft_index_to_string("rNames_idx", "rNames_remap") %>%
collect
table(ft_string2idx$rNames_idx,ft_string2idx$rNames_remap) # show mapping
load("array-all.Rdata")
feats <- array.dfs[-1]
descrCor <- cor(feats)
highlyCorDescr <- findCorrelation(descrCor, cutoff = .95)
filteredDescr <- feats[,-highlyCorDescr]
array-all-trim<-cbind(array.dfs[1],filteredDescr)
View(array.dfs)
cbind(array.dfs[1])
cbind(array.dfs[1],filteredDescr)
array.all.trim<-cbind(array.dfs[1],filteredDescr)
write.csv(array.all.trim,file = "array.all.trim.csv",row.names = FALSE) # write out feature matrix to .csv
rm(array.dfs,feats,descrCor,highlyCorDescr,filteredDescr,array-all.trim) #clean up
rm(array.dfs,feats,descrCor,highlyCorDescr,filteredDescr,array.all.trim) #clean up
library(dplyr)
library(sparklyr)
# connect to instance
sc <- spark_connect(master = "local")
features_tbl <- spark_read_csv(sc, name = 'featLib', path = '~/Research/cvCells/macro-tests/in-grey-seg/array.all.trim.csv')
# fit linear model
partitions <- features_tbl %>%
sdf_partition(training = 0.75, test = 0.25, seed = 1099)
fit <- partitions$training %>%
ml_linear_regression(response = "x_0_s_area", features = c("x_0_s_perimeter", "x_0_m_majoraxis"))
summary(fit)
# kmeans test
kmeans_model <- features_tbl %>%
select(x_0_s_area, x_0_m_majoraxis) %>%
ml_kmeans(centers = 3)
print(kmeans_model)
# predict the associated class
predicted <- sdf_predict(kmeans_model, features_tbl) %>%
collect
table(predicted$rNames_tag, predicted$prediction)
library(ggplot2)
sdf_predict(kmeans_model) %>%
collect() %>%
ggplot(aes(x_0_s_area, x_0_m_majoraxis)) +
geom_point(aes(x_0_m_majoraxis, x_0_s_area, col = factor(prediction + 1)),
size = 2, alpha = 0.5) +
geom_point(data = kmeans_model$centers, aes(x_0_m_majoraxis, x_0_s_area),
col = scales::muted(c("red", "green", "blue")),
pch = 'x', size = 12) +
scale_color_discrete(name = "Predicted Cluster",
labels = paste("Cluster", 1:3)) +
labs(
x = "x_0_m_majoraxis",
y = "x_0_s_area",
title = "K-Means Clustering",
subtitle = "Use Spark.ML to predict cluster membership with this dataset."
)
# rf model
rf_model <- features_tbl %>%
ml_random_forest(rNames_tag ~ x_0_s_area + x_0_m_majoraxis, type = "classification")
rf_predict <- sdf_predict(rf_model, features_tbl) %>%
ft_string_indexer("rNames_tag", "rNames_idx") %>%
collect
# print the classification results
table(rf_predict$rNames_idx, rf_predict$prediction)
ft_string2idx <- features_tbl %>%
ft_string_indexer("rNames_tag", "rNames_idx") %>%
ft_index_to_string("rNames_idx", "rNames_remap") %>%
collect
table(ft_string2idx$rNames_idx,ft_string2idx$rNames_remap) # show mapping
