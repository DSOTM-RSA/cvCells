geom_node_point(aes(filter=leaf, color=species)) +
coord_fixed() +
ggforce::theme_no_axes()
ggraph(graph = irisDen2, layout = 'dendrogram', repel = FALSE, circular = TRUE,
ratio = 20.5) +
geom_edge_elbow() +
geom_node_text(aes(x = x*1.05, y=y*1.05, filter=leaf,
angle = nAngle(x, y), label = label),
size=3, hjust='outward') +
geom_node_point(aes(filter=leaf, color=species)) +
coord_fixed() +
ggforce::theme_no_axes()
ggraph(graph = irisDen2, layout = 'dendrogram', repel = FALSE, circular = TRUE,
ratio = 0.5) +
geom_edge_elbow() +
geom_node_text(aes(x = x*1.05, y=y*1.05, filter=leaf,
angle = nAngle(x, y), label = label),
size=3, hjust='outward') +
geom_node_point(aes(filter=leaf, color=species)) +
coord_fixed() +
ggforce::theme_no_axes()
?ggraph
install.packages("sparklyr")
library(sparklyr)
spark_install(version = "1.6.2")
sc <- spark_connect(master = "local")
library(dplyr)
iris_tbl <- copy_to(sc, iris)
flights_tbl <- copy_to(sc, nycflights13::flights, "flights")
batting_tbl <- copy_to(sc, Lahman::Batting, "batting")
flights_tbl %>% filter(dep_delay == 2)
delay <- flights_tbl %>%
group_by(tailnum) %>%
summarise(count = n(), dist = mean(distance), delay = mean(arr_delay)) %>%
filter(count > 20, dist < 2000, !is.na(delay)) %>%
collect()
library(ggplot2)
ggplot(delay, aes(dist, delay)) +
geom_point(aes(size = count), alpha = 1/2) +
geom_smooth() +
scale_size_area(max_size = 2)
batting_tbl %>%
select(playerID, yearID, teamID, G, AB:H) %>%
arrange(playerID, yearID, teamID) %>%
group_by(playerID) %>%
filter(min_rank(desc(H)) <= 2 & H > 0)
library(DBI)
iris_preview <- dbGetQuery(sc, "SELECT * FROM iris LIMIT 10")
mtcars_tbl <- copy_to(sc, mtcars)
partitions <- mtcars_tbl %>%
filter(hp >= 100) %>%
mutate(cyl8 = cyl == 8) %>%
sdf_partition(training = 0.5, test = 0.5, seed = 1099)
fit <- partitions$training %>%
ml_linear_regression(response = "mpg", features = c("wt", "cyl"))
summary(fit)
training <- as_h2o_frame(partitions$training)
test <- as_h2o_frame(partitions$test)
# Remove previous versions of h2o R package
if ("package:h2o" %in% search()) detach("package:h2o", unload=TRUE)
if ("h2o" %in% rownames(installed.packages())) remove.packages("h2o")
pkgs <- c("methods","statmod","stats","graphics",
"RCurl","jsonlite","tools","utils")
for (pkg in pkgs) {
if (!(pkg %in% rownames(installed.packages()))) install.packages(pkg)
}
install.packages("h2o", type = "source",
repos = "http://h2o-release.s3.amazonaws.com/h2o/rel-turing/6/R")
library(devtools)
devtools::install_github("h2oai/sparkling-water", subdir = "/r/rsparkling")
training <- as_h2o_frame(partitions$training)
test <- as_h2o_frame(partitions$test)
library(rsparkling)
training <- as_h2o_frame(partitions$training)
test <- as_h2o_frame(partitions$test)
h2o.init()
training <- as_h2o_frame(partitions$training)
test <- as_h2o_frame(partitions$test)
training <- as_h2o_frame(x = partitions$training)
training <- as_h2o_frame(sc = sc,x = partitions$training)
sc <- spark_connect("local", version = "1.6.2")
mtcars_tbl <- copy_to(sc, mtcars, "mtcars", overwrite = TRUE)
partitions <- mtcars_tbl %>%
filter(hp >= 100) %>%
mutate(cyl8 = cyl == 8) %>%
sdf_partition(training = 0.5, test = 0.5, seed = 1099)
training <- as_h2o_frame(sc, partitions$training)
test <- as_h2o_frame(sc, partitions$test)
glm_model <- h2o.glm(x = c("wt", "cyl"),
y = "mpg",
training_frame = training,
lambda_search = TRUE)
partitions <- h2o.splitFrame(as_h2o_frame(mtcars_tbl), 0.5))
partitions <- h2o.splitFrame(as_h2o_frame(mtcars_tbl), 0.5)
partitions <- h2o.splitFrame(data = as_h2o_frame(mtcars_tbl), 0.5)
library(sparklyr)
library(rsparkling)
library(dplyr)
sc <- spark_connect("local", version = "1.6.2")
mtcars_tbl <- copy_to(sc, mtcars, "mtcars", overwrite = TRUE)
partitions <- mtcars_tbl %>%
filter(hp >= 100) %>%
mutate(cyl8 = cyl == 8) %>%
sdf_partition(training = 0.5, test = 0.5, seed = 1099)
training <- as_h2o_frame(sc, partitions$training)
test <- as_h2o_frame(sc, partitions$test)
glm_model <- h2o.glm(x = c("wt", "cyl"),
y = "mpg",
training_frame = training,
lambda_search = TRUE)
print(glm_model)
library(ggplot2)
pred <- h2o.predict(glm_model, newdata = test)
# convert from H2O Frame to Spark DataFrame
predicted <- as_spark_dataframe(sc, pred)
actual <- partitions$test %>%
select(mpg) %>%
collect() %>%
`[[`("mpg")
data <- data.frame(
predicted = predicted,
actual    = actual
)
names(data) <- c("predicted", "actual")
ggplot(data, aes(x = actual, y = predicted)) +
geom_abline(lty = "dashed", col = "red") +
geom_point() +
theme(plot.title = element_text(hjust = 0.5)) +
coord_fixed(ratio = 1) +
labs(
x = "Actual Fuel Consumption",
y = "Predicted Fuel Consumption",
title = "Predicted vs. Actual Fuel Consumption"
)
library(dplyr)
sc <- spark_connect("local", version = "1.6.2")
iris_tbl <- copy_to(sc, iris, "iris", overwrite = TRUE)
iris_tbl
iris_hf <- as_h2o_frame(sc, iris_tbl)
kmeans_model <- h2o.kmeans(training_frame = iris_hf,
x = 3:4,
k = 3,
seed = 1)
h2o.centers(kmeans_model)
pca_model <- h2o.prcomp(training_frame = iris_hf,
x = 1:4,
k = 4,
seed = 1)
print(pca_model)
y <- "Species"
x <- setdiff(names(iris_hf), y)
iris_hf[,y] <- as.factor(iris_hf[,y])
splits <- h2o.splitFrame(iris_hf, seed = 1)
rf_model <- h2o.randomForest(x = x,
y = y,
training_frame = splits[[1]],
validation_frame = splits[[2]],
nbins = 32,
max_depth = 5,
ntrees = 20,
seed = 1)
h2o.confusionMatrix(rf_model, valid = TRUE)
h2o.varimp_plot(rf_model)
gbm_model <- h2o.gbm(x = x,
y = y,
training_frame = splits[[1]],
validation_frame = splits[[2]],
ntrees = 20,
max_depth = 3,
learn_rate = 0.01,
col_sample_rate = 0.7,
seed = 1)
h2o.confusionMatrix(gbm_model, valid = TRUE)
path <- system.file("extdata", "prostate.csv", package = "h2o")
prostate_df <- spark_read_csv(sc, "prostate", path)
head(prostate_df)
prostate_hf <- as_h2o_frame(sc, prostate_df)
splits <- h2o.splitFrame(prostate_hf, seed = 1)
y <- "VOL"
#remove response and ID cols
x <- setdiff(names(prostate_hf), c("ID", y))
dl_fit <- h2o.deeplearning(x = x, y = y,
training_frame = splits[[1]],
epochs = 15,
activation = "Rectifier",
hidden = c(10, 5, 10),
input_dropout_ratio = 0.7)
h2o.performance(dl_fit, newdata = splits[[2]])
splits <- h2o.splitFrame(prostate_hf, seed = 1)
y <- "VOL"
#remove response and ID cols
x <- setdiff(names(prostate_hf), c("ID", y))
gbm_params1 <- list(learn_rate = c(0.01, 0.1),
max_depth = c(3, 5, 9),
sample_rate = c(0.8, 1.0),
col_sample_rate = c(0.2, 0.5, 1.0))
gbm_grid1 <- h2o.grid("gbm", x = x, y = y,
grid_id = "gbm_grid1",
training_frame = splits[[1]],
validation_frame = splits[[1]],
ntrees = 100,
seed = 1,
hyper_params = gbm_params1)
gbm_gridperf1 <- h2o.getGrid(grid_id = "gbm_grid1",
sort_by = "mse",
decreasing = FALSE)
print(gbm_gridperf1)
gbm_params2 <- list(learn_rate = seq(0.01, 0.1, 0.01),
max_depth = seq(2, 10, 1),
sample_rate = seq(0.5, 1.0, 0.1),
col_sample_rate = seq(0.1, 1.0, 0.1))
search_criteria2 <- list(strategy = "RandomDiscrete",
max_models = 50)
gbm_grid2 <- h2o.grid("gbm", x = x, y = y,
grid_id = "gbm_grid2",
training_frame = splits[[1]],
validation_frame = splits[[2]],
ntrees = 100,
seed = 1,
hyper_params = gbm_params2,
search_criteria = search_criteria2)
gbm_params2 <- list(learn_rate = seq(0.01, 0.1, 0.01),
max_depth = seq(2, 10, 1),
sample_rate = seq(0.5, 1.0, 0.1),
col_sample_rate = seq(0.1, 1.0, 0.1))
search_criteria2 <- list(strategy = "RandomDiscrete",max_runtime_secs=60)
gbm_grid2 <- h2o.grid("gbm", x = x, y = y,
grid_id = "gbm_grid2",
training_frame = splits[[1]],
validation_frame = splits[[2]],
ntrees = 100,
seed = 1,
hyper_params = gbm_params2,
search_criteria = search_criteria2)
gbm_gridperf2 <- h2o.getGrid(grid_id = "gbm_grid2",
sort_by = "mse",
decreasing = FALSE)
gbm_gridperf2@summary_table[1,]
h2o.saveModel(my_model, path = "/Users/danny/h2omodels")
mod<-gbm_gridperf2@summary_table[1,]
h2o.saveModel(mod, path = "/Users/danny")
h2o.saveModel(dl_fit, path = "/Users/danny")
plot(cars)
plot(cars)
library(readr)
MAP_dat <- read_delim("~/Research/MAP/data/MAP_dat.tsv",
"\t", escape_double = FALSE, trim_ws = TRUE)
View(MAP_dat)
library(readr)
MAP_dat <- read_delim("~/Research/MAP/data/MAP_dat.tsv",
"\t", escape_double = FALSE, trim_ws = TRUE)
View(MAP_dat)
View(MAP_dat)
library(readxl)
GeoB20305_7_alldata <- read_excel("~/Research/MAP/data/GeoB20305-7_alldata.xlsx",
sheet = "Tabelle1")
View(GeoB20305_7_alldata)
library(readxl)
test <- read_excel("~/Research/MAP/data/GeoB20305-7_alldata.xlsx")
View(GeoB20305_7_alldata)
View(test)
suppressMessages(library(dplyr))
suppressMessages(library(purrr))
library(tidyr)
set.seed(4561)
(nested_iris <- iris %>%
group_by(Species)
)
(nested_iris <- iris %>%
group_by(Species) %>%   # prep for work by Species
nest())
View(nested_iris)
(nested_iris <- iris %>%
group_by(Species) %>%   # prep for work by Species
nest() %>%              # --> one row per Species
mutate(n = c(2, 5, 3)))
View(nested_iris)
(sampled_iris <- nested_iris %>%
mutate(samp = map2(data, n, sample_n)))
View(sampled_iris)
sampled_iris %>%
select(Species, samp) %>%
unnest()
results<-sampled_iris %>%
select(Species, samp) %>%
unnest()
View(results)
library(modelr)
library(tidyverse)
library(gapminder)
gapminder
install.packages("gapminder")
library(gapminder)
gapminder
gapminder %>%
ggplot(aes(year, lifeExp, group = country)) +
geom_line(alpha = 1/3)
nz <- filter(gapminder, country == "New Zealand")
nz %>%
ggplot(aes(year, lifeExp)) +
geom_line() +
ggtitle("Full data = ")
nz_mod <- lm(lifeExp ~ year, data = nz)
nz %>%
add_predictions(nz_mod) %>%
ggplot(aes(year, pred)) +
geom_line() +
ggtitle("Linear trend + ")
nz %>%
add_residuals(nz_mod) %>%
ggplot(aes(year, resid)) +
geom_hline(yintercept = 0, colour = "white", size = 3) +
geom_line() +
ggtitle("Remaining pattern")
by_country <- gapminder %>%
group_by(country, continent)
View(by_country)
by_country <- gapminder %>%
group_by(country, continent) %>%
nest()
by_country
by_country$data[[1]]
country_model <- function(df) {
lm(lifeExp ~ year, data = df)
}
models <- map(by_country$data, country_model)
by_country <- by_country %>%
mutate(model = map(data, country_model))
by_country %>%
filter(continent == "Europe")
by_country %>%
arrange(continent, country)
by_country <- by_country %>%
mutate(
resids = map2(data, model, add_residuals)
)
resids <- unnest(by_country, resids)
resids
resids %>%
ggplot(aes(year, resid)) +
geom_line(aes(group = country), alpha = 1 / 3) +
geom_smooth(se = FALSE)
resids %>%
ggplot(aes(year, resid, group = country)) +
geom_line(alpha = 1 / 3) +
facet_wrap(~continent)
broom::glance(nz_mod)
by_country %>%
mutate(glance = map(model, broom::glance)) %>%
unnest(glance)
glance <- by_country %>%
mutate(glance = map(model, broom::glance)) %>%
unnest(glance, .drop = TRUE)
View(glance)
glance %>%
arrange(r.squared)
glance %>%
ggplot(aes(continent, r.squared)) +
geom_jitter(width = 0.5)
bad_fit <- filter(glance, r.squared < 0.25)
gapminder %>%
semi_join(bad_fit, by = "country") %>%
ggplot(aes(year, lifeExp, colour = country)) +
geom_line()
gapminder %>%
group_by(country, continent) %>%
nest()
gapminder %>%
nest(year:gdpPercap)
setwd("~/Research/cvCells/macro-tests/in-grey-seg")
library(sparklyr)
spark_install(version = "1.6.2")
sc <- spark_connect(master = "local")
accidents <- spark_read_csv(sc, name = 'accidents', path = '~/Research/cvCells/macro-tests/in-grey-seg/array-all.csv')
library(dplyr)
mtcars_tbl <- copy_to(sc, mtcars)
iris_tbl <- copy_to(sc, iris)
flights_tbl <- copy_to(sc, nycflights13::flights, "flights")
partitions <- accidents %>%
sdf_partition(training = 0.75, test = 0.25, seed = 1099)
fit <- partitions$training %>%
ml_linear_regression(response = "x_0_s_area", features = c("x_0_s_perimeter", "x_0_m_majoraxis"))
summary(fit)
kmeans_model <- accidents %>%
select(x_0_s_area, x_0_m_majoraxis) %>%
ml_kmeans(centers = 3)
print(kmeans_model)
predicted <- sdf_predict(kmeans_model, accidents) %>%
collect
table(predicted$rNames_tag, predicted$prediction)
sdf_predict(kmeans_model) %>%
collect() %>%
ggplot(aes(x_0_s_area, x_0_m_majoraxis)) +
geom_point(aes(x_0_m_majoraxis, x_0_s_area, col = factor(prediction + 1)),
size = 2, alpha = 0.5) +
geom_point(data = kmeans_model$centers, aes(x_0_m_majoraxis, x_0_s_area),
col = scales::muted(c("red", "green", "blue")),
pch = 'x', size = 12) +
scale_color_discrete(name = "Predicted Cluster",
labels = paste("Cluster", 1:3)) +
labs(
x = "Petal Length",
y = "Petal Width",
title = "K-Means Clustering",
subtitle = "Use Spark.ML to predict cluster membership with the iris dataset."
)
library(ggplot2)
sdf_predict(kmeans_model) %>%
collect() %>%
ggplot(aes(x_0_s_area, x_0_m_majoraxis)) +
geom_point(aes(x_0_m_majoraxis, x_0_s_area, col = factor(prediction + 1)),
size = 2, alpha = 0.5) +
geom_point(data = kmeans_model$centers, aes(x_0_m_majoraxis, x_0_s_area),
col = scales::muted(c("red", "green", "blue")),
pch = 'x', size = 12) +
scale_color_discrete(name = "Predicted Cluster",
labels = paste("Cluster", 1:3)) +
labs(
x = "Petal Length",
y = "Petal Width",
title = "K-Means Clustering",
subtitle = "Use Spark.ML to predict cluster membership with the iris dataset."
)
sdf_predict(kmeans_model) %>%
collect() %>%
ggplot(aes(x_0_s_area, x_0_m_majoraxis)) +
geom_point(aes(x_0_m_majoraxis, x_0_s_area, col = factor(prediction + 1)),
size = 2, alpha = 0.5) +
geom_point(data = kmeans_model$centers, aes(x_0_m_majoraxis, x_0_s_area),
col = scales::muted(c("red", "green", "blue")),
pch = 'x', size = 12) +
scale_color_discrete(name = "Predicted Cluster",
labels = paste("Cluster", 1:3)) +
labs(
x = "x_0_m_majoraxis",
y = "x_0_s_area",
title = "K-Means Clustering",
subtitle = "Use Spark.ML to predict cluster membership with this dataset."
)
beaver <- beaver2
View(beaver)
beaver$activ <- factor(beaver$activ, labels = c("Non-Active", "Active"))
copy_to(sc, beaver, "beaver")
beaver_tbl <- tbl(sc, "beaver")
rf_model <- accidents %>%
ml_random_forest(rNames.tag ~ x_0_s_area + x_0_m_majoraxis, type = "classification")
iris_tbl$Species
iris_tbl$con
iris_tbl$src
iris_tbl$src$con
iris_tbl$src$ops
iris_tbl$ops
iris_tbl$ops$vars
iris_tbl$ops$x
rf_model <- accidents %>%
ml_random_forest(rNames_tag ~ x_0_s_area + x_0_m_majoraxis, type = "classification")
rf_predict <- sdf_predict(rf_model, iris_tbl) %>%
ft_string_indexer("Species", "Species_idx") %>%
collect
rf_predict <- sdf_predict(rf_model, iris_tbl) %>%
ft_string_indexer("rNames_tag", "rNames_idx") %>%
collect
rf_predict <- sdf_predict(rf_model, accidents) %>%
ft_string_indexer("rNames_tag", "rNames_idx") %>%
collect
table(rf_predict$rNames_idx, rf_predict$prediction)
ft_string2idx <- accidents %>%
ft_string_indexer("rNames_tag", "rNames_tag") %>%
ft_index_to_string("rNames_tag", "rNames_remap") %>%
collect
ft_string2idx <- accidents %>%
ft_string_indexer("rNames_tag", "rNames_ind") %>%
ft_index_to_string("rNames_ind", "rNames_remap") %>%
collect
ft_string2idx <- accidents %>%
ft_string_indexer("rNames_tag", "rNames_idx") %>%
ft_index_to_string("rNames_idx", "rNames_remap") %>%
collect
table(ft_string2idx$rNames_tag, ft_string2idx$rNames_remap)
rf_predict2 <- sdf_predict(rf_model, accidents) %>% collect
table(rf_predict2$rNames_tag, rf_predict2$prediction)
rf_predict <- sdf_predict(rf_model, accidents) %>%
ft_string_indexer("rNames_tag", "rNames_idx") %>%
collect
table(rf_predict$rNames_idx, rf_predict$prediction)
rf_predict$rNames_idx
rf_predict$prediction
ft_string2idx <- accidents %>%
ft_string_indexer("rNames_tag", "rNames_idx") %>%
ft_index_to_string("rNames_idx", "rNames_remap") %>%
collect
table(ft_string2idx$rNames_tag, ft_string2idx$rNames_remap)
ft_string2idx <- accidents %>%
ft_string_indexer("rNames_tag", "rNames_idx") %>%
ft_index_to_string("rNames_idx", "rNames_remap") %>%
collect
ft_string2idx
ft_string2idx$rNames_remap
table(ft_string2idx$rNames_tag, ft_string2idx$rNames_remap)
table(ft_string2idx$rNames_tag,ft_string2idx$rNames_remap)
table(ft_string2idx$rNames_remap, rf_predict$prediction)
table(ft_string2idx$rNames_tag,ft_string2idx$rNames_remap)
table(rf_predict$rNames_idx, rf_predict$prediction)
table(ft_string2idx$rNames_tag,ft_string2idx$rNames_remap)
table(ft_string2idx$rNames_idx,ft_string2idx$rNames_remap)
table(ft_string2idx$rNames_tag,ft_string2idx$rNames_remap)
rf_predict$rNames_idx
rf_predict$rNames_tag
table(rf_predict$rNames_idx, rf_predict$prediction)
table(ft_string2idx$rNames_idx,ft_string2idx$rNames_remap) # show mapping
table(rf_predict$rNames_idx, rf_predict$prediction)
table(rf_predict$rNames_idx, rf_predict$prediction)
