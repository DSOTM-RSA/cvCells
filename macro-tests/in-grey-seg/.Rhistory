MAP_dat <- read_delim("~/Research/MAP/data/MAP_dat.tsv",
"\t", escape_double = FALSE, trim_ws = TRUE)
View(MAP_dat)
library(readr)
MAP_dat <- read_delim("~/Research/MAP/data/MAP_dat.tsv",
"\t", escape_double = FALSE, trim_ws = TRUE)
View(MAP_dat)
View(MAP_dat)
library(readxl)
GeoB20305_7_alldata <- read_excel("~/Research/MAP/data/GeoB20305-7_alldata.xlsx",
sheet = "Tabelle1")
View(GeoB20305_7_alldata)
library(readxl)
test <- read_excel("~/Research/MAP/data/GeoB20305-7_alldata.xlsx")
View(GeoB20305_7_alldata)
View(test)
suppressMessages(library(dplyr))
suppressMessages(library(purrr))
library(tidyr)
set.seed(4561)
(nested_iris <- iris %>%
group_by(Species)
)
(nested_iris <- iris %>%
group_by(Species) %>%   # prep for work by Species
nest())
View(nested_iris)
(nested_iris <- iris %>%
group_by(Species) %>%   # prep for work by Species
nest() %>%              # --> one row per Species
mutate(n = c(2, 5, 3)))
View(nested_iris)
(sampled_iris <- nested_iris %>%
mutate(samp = map2(data, n, sample_n)))
View(sampled_iris)
sampled_iris %>%
select(Species, samp) %>%
unnest()
results<-sampled_iris %>%
select(Species, samp) %>%
unnest()
View(results)
library(modelr)
library(tidyverse)
library(gapminder)
gapminder
install.packages("gapminder")
library(gapminder)
gapminder
gapminder %>%
ggplot(aes(year, lifeExp, group = country)) +
geom_line(alpha = 1/3)
nz <- filter(gapminder, country == "New Zealand")
nz %>%
ggplot(aes(year, lifeExp)) +
geom_line() +
ggtitle("Full data = ")
nz_mod <- lm(lifeExp ~ year, data = nz)
nz %>%
add_predictions(nz_mod) %>%
ggplot(aes(year, pred)) +
geom_line() +
ggtitle("Linear trend + ")
nz %>%
add_residuals(nz_mod) %>%
ggplot(aes(year, resid)) +
geom_hline(yintercept = 0, colour = "white", size = 3) +
geom_line() +
ggtitle("Remaining pattern")
by_country <- gapminder %>%
group_by(country, continent)
View(by_country)
by_country <- gapminder %>%
group_by(country, continent) %>%
nest()
by_country
by_country$data[[1]]
country_model <- function(df) {
lm(lifeExp ~ year, data = df)
}
models <- map(by_country$data, country_model)
by_country <- by_country %>%
mutate(model = map(data, country_model))
by_country %>%
filter(continent == "Europe")
by_country %>%
arrange(continent, country)
by_country <- by_country %>%
mutate(
resids = map2(data, model, add_residuals)
)
resids <- unnest(by_country, resids)
resids
resids %>%
ggplot(aes(year, resid)) +
geom_line(aes(group = country), alpha = 1 / 3) +
geom_smooth(se = FALSE)
resids %>%
ggplot(aes(year, resid, group = country)) +
geom_line(alpha = 1 / 3) +
facet_wrap(~continent)
broom::glance(nz_mod)
by_country %>%
mutate(glance = map(model, broom::glance)) %>%
unnest(glance)
glance <- by_country %>%
mutate(glance = map(model, broom::glance)) %>%
unnest(glance, .drop = TRUE)
View(glance)
glance %>%
arrange(r.squared)
glance %>%
ggplot(aes(continent, r.squared)) +
geom_jitter(width = 0.5)
bad_fit <- filter(glance, r.squared < 0.25)
gapminder %>%
semi_join(bad_fit, by = "country") %>%
ggplot(aes(year, lifeExp, colour = country)) +
geom_line()
gapminder %>%
group_by(country, continent) %>%
nest()
gapminder %>%
nest(year:gdpPercap)
install.packages(c("globals", "h2o", "snow"))
if ("package:h2o" %in% search()) detach("package:h2o", unload=TRUE)
if ("h2o" %in% rownames(installed.packages())) remove.packages("h2o")
install.packages("h2o", type = "source",
repos = "http://h2o-release.s3.amazonaws.com/h2o/rel-turing/6/R")
library(sparklyr)
library(sparklyr)
library(rsparkling)
library(dplyr)
sc <- spark_connect("local", version = "1.6.2")
mtcars_tbl <- copy_to(sc, mtcars, "mtcars", overwrite = TRUE)
partitions <- mtcars_tbl %>%
filter(hp >= 100) %>%
mutate(cyl8 = cyl == 8) %>%
sdf_partition(training = 0.5, test = 0.5, seed = 1099)
training <- as_h2o_frame(sc, partitions$training)
test <- as_h2o_frame(sc, partitions$test)
glm_model <- h2o.glm(x = c("wt", "cyl"),
y = "mpg",
training_frame = training,
lambda_search = TRUE)
print(glm_model)
library(ggplot2)
# compute predicted values on our test dataset
pred <- h2o.predict(glm_model, newdata = test)
# convert from H2O Frame to Spark DataFrame
predicted <- as_spark_dataframe(sc, pred)
# extract the true 'mpg' values from our test dataset
actual <- partitions$test %>%
select(mpg) %>%
collect() %>%
`[[`("mpg")
# produce a data.frame housing our predicted + actual 'mpg' values
data <- data.frame(
predicted = predicted,
actual    = actual
)
# a bug in data.frame does not set colnames properly; reset here
names(data) <- c("predicted", "actual")
# plot predicted vs. actual values
ggplot(data, aes(x = actual, y = predicted)) +
geom_abline(lty = "dashed", col = "red") +
geom_point() +
theme(plot.title = element_text(hjust = 0.5)) +
coord_fixed(ratio = 1) +
labs(
x = "Actual Fuel Consumption",
y = "Predicted Fuel Consumption",
title = "Predicted vs. Actual Fuel Consumption"
)
iris_tbl <- copy_to(sc, iris, "iris", overwrite = TRUE)
iris_tbl
iris_hf <- as_h2o_frame(sc, iris_tbl)
kmeans_model <- h2o.kmeans(training_frame = iris_hf,
x = 3:4,
k = 3,
seed = 1)
h2o.centroid_stats(kmeans_model)
pca_model <- h2o.prcomp(training_frame = iris_hf,
x = 1:4,
k = 4,
seed = 1)
print(pca_model)
y <- "Species"
x <- setdiff(names(iris_hf), y)
iris_hf[,y] <- as.factor(iris_hf[,y])
splits <- h2o.splitFrame(iris_hf, seed = 1)
rf_model <- h2o.randomForest(x = x,
y = y,
training_frame = splits[[1]],
validation_frame = splits[[2]],
nbins = 32,
max_depth = 5,
ntrees = 20,
seed = 1)
h2o.confusionMatrix(rf_model, valid = TRUE)
h2o.varimp_plot(rf_model)
gbm_model <- h2o.gbm(x = x,
y = y,
training_frame = splits[[1]],
validation_frame = splits[[2]],
ntrees = 20,
max_depth = 3,
learn_rate = 0.01,
col_sample_rate = 0.7,
seed = 1)
h2o.confusionMatrix(gbm_model, valid = TRUE)
path <- system.file("extdata", "prostate.csv", package = "h2o")
prostate_df <- spark_read_csv(sc, "prostate", path)
head(prostate_df)
prostate_hf <- as_h2o_frame(sc, prostate_df)
splits <- h2o.splitFrame(prostate_hf, seed = 1)
y <- "VOL"
x <- setdiff(names(prostate_hf), c("ID", y))
dl_fit <- h2o.deeplearning(x = x, y = y,
training_frame = splits[[1]],
epochs = 15,
activation = "Rectifier",
hidden = c(10, 5, 10),
input_dropout_ratio = 0.7)
h2o.performance(dl_fit, newdata = splits[[2]])
splits <- h2o.splitFrame(prostate_hf, seed = 1)
y <- "VOL"
#remove response and ID cols
x <- setdiff(names(prostate_hf), c("ID", y))
# GBM hyperparamters
gbm_params1 <- list(learn_rate = c(0.01, 0.1),
max_depth = c(3, 5, 9),
sample_rate = c(0.8, 1.0),
col_sample_rate = c(0.2, 0.5, 1.0))
# Train and validate a grid of GBMs
gbm_grid1 <- h2o.grid("gbm", x = x, y = y,
grid_id = "gbm_grid1",
training_frame = splits[[1]],
validation_frame = splits[[1]],
ntrees = 100,
seed = 1,
hyper_params = gbm_params1)
gbm_gridperf1 <- h2o.getGrid(grid_id = "gbm_grid1",
sort_by = "mse",
decreasing = FALSE)
print(gbm_gridperf1)
gbm_params2 <- list(learn_rate = seq(0.01, 0.1, 0.01),
max_depth = seq(2, 10, 1),
sample_rate = seq(0.5, 1.0, 0.1),
col_sample_rate = seq(0.1, 1.0, 0.1))
search_criteria2 <- list(strategy = "RandomDiscrete",
max_models = 150)
# Train and validate a grid of GBMs
gbm_grid2 <- h2o.grid("gbm", x = x, y = y,
grid_id = "gbm_grid2",
training_frame = splits[[1]],
validation_frame = splits[[2]],
ntrees = 100,
seed = 1,
hyper_params = gbm_params2,
search_criteria = search_criteria2)
gbm_gridperf2 <- h2o.getGrid(grid_id = "gbm_grid2",
sort_by = "mse",
decreasing = FALSE)
gbm_gridperf2@summary_table[1,]
install.packages("rbokeh")
library(sparklyr)
library(dplyr)
library(babynames)
library(ggplot2)
library(dygraphs)
library(rbokeh)
install.packages("dygraphs")
sc <- spark_connect(master = "local")
babynames_tbl <- copy_to(sc, babynames, "babynames")
applicants_tbl <- copy_to(sc, applicants, "applicants")
birthsYearly <- applicants_tbl %>% mutate(male = ifelse(sex=="M",n_all,0), female=ifelse(sex== "F",n_all,0))
birthsYearly <- applicants_tbl %>% mutate(male = ifelse(sex=="M",n_all,0), female=ifelse(sex== "F",n_all,0)) %>% group_by(year) %>% summarize(Male=sum(male)/ 1000000, Female = sum(female) / 1000000) %>% arrange(year) %>% collect
birthsYearly <- applicants_tbl %>% mutate(male = ifelse(sex=="M",n_all,0), female=ifelse(sex== "F",n_all,0)) %>% collect()
View(birthsYearly)
birthsYearly <- applicants_tbl %>% mutate(male = ifelse(sex=="M",n_all,0), female=ifelse(sex== "F",n_all,0)) %>% group_by(year) %>% summarize(Male=sum(male)/ 1000000, Female = sum(female) / 1000000) %>% arrange(year) %>% collect
View(birthsYearly)
birthsYearly %>%
dygraph(main = "Total US Births (SSN)", ylab = "Millions") %>%
dySeries("Female") %>%
dySeries("Male") %>%
dyOptions(stackedGraph = TRUE) %>%
dyRangeSelector(height = 20)
install.packages("dygraphs")
library(dygraphs)
birthsYearly %>%
dygraph(main = "Total US Births (SSN)", ylab = "Millions") %>%
dySeries("Female") %>%
dySeries("Male") %>%
dyOptions(stackedGraph = TRUE) %>%
dyRangeSelector(height = 20)
topNames_tbl <- babynames_tbl %>% filter(year >=1986) %>% group_by(name,sex) %>% summarize(count =as.numeric(sum(n)))
topNames_tbl <- babynames_tbl %>% filter(year >=1986) %>% group_by(name,sex) %>% summarize(count =as.numeric(sum(n))) %>% collect()
View(topNames_tbl)
View(birthsYearly)
topNames_tbl <- babynames_tbl %>%
filter(year >= 1986) %>%
group_by(name, sex) %>%
summarize(count = as.numeric(sum(n))) %>%
filter(count > 1000) %>%
select(name, sex) %>% collect()
View(topNames_tbl)
filteredNames_tbl <- babynames_tbl %>%
filter(year >= 1986) %>%
inner_join(topNames_tbl) %>% collect()
filteredNames_tbl <- babynames_tbl %>%
filter(year >= 1986) %>%
inner_join(topNames_tbl)
topNames_tbl <- babynames_tbl %>%
filter(year >= 1986) %>%
group_by(name, sex) %>%
summarize(count = as.numeric(sum(n))) %>%
filter(count > 1000) %>%
select(name, sex)
filteredNames_tbl <- babynames_tbl %>%
filter(year >= 1986) %>%
inner_join(topNames_tbl)
filteredNames_tbl <- babynames_tbl %>%
filter(year >= 1986) %>%
inner_join(topNames_tbl) %>% collect()
filteredNames_tbl <- babynames_tbl %>%
filter(year >= 1986) %>%
inner_join(topNames_tbl)
yearlyNames_tbl <- filteredNames_tbl %>%
group_by(year, name, sex) %>%
summarize(count = as.numeric(sum(n)))
sdf_register(yearlyNames_tbl, "yearlyNames")
topNames_tbl <- babynames_tbl %>%
filter(year >= 1986) %>%
group_by(name, sex) %>%
summarize(count = as.numeric(sum(n)))
topNames_tbl <- babynames_tbl %>%
filter(year >= 1986) %>%
group_by(name, sex) %>%
summarize(count = as.numeric(sum(n))) %>% collect()
View(topNames_tbl)
View(birthsYearly)
View(birthsYearly)
data("babynames")
data("babynames")
View(babynames)
res <-babynames %>% filter(name=="Mary")
View(res)
res <-babynames %>% filter(name=="Mary" | sex == "M")
View(res)
res <-babynames %>% filter(name=="Mary" , sex == "M")
View(res)
res <-babynames %>% filter(name=="Mary" , sex == "F")
View(res)
plot(res$year,res$prop)
plot(res$year,res$prop*100)
res <-babynames %>% filter(name=="Beyonce" , sex == "F")
plot(res$year,res$prop*100)
res <-babynames %>% filter(name=="Salvador" , sex == "M")
plot(res$year,res$prop*100)
res <-babynames %>% filter(name=="Daniel" , sex == "M")
plot(res$year,res$prop*100)
res <-babynames %>% filter(name=="George" , sex == "M")
plot(res$year,res$prop*100)
res <-babynames %>% filter(name=="John" , sex == "M")
plot(res$year,res$prop*100)
res <-babynames %>% filter(name=="Paul" , sex == "M")
plot(res$year,res$prop*100)
res <-babynames %>% filter(name=="Jennifer" , sex == "F")
plot(res$year,res$prop*100)
res <-babynames %>% filter(name=="Audrey" , sex == "F")
plot(res$year,res$prop*100)
res <-babynames %>% filter(name=="Marilyn" , sex == "F")
plot(res$year,res$prop*100)
res <-babynames %>% filter(name=="Elvis" , sex == "M")
plot(res$year,res$prop*100)
res <-babynames %>% filter(name=="Michael" , sex == "M")
plot(res$year,res$prop*100)
res <-babynames %>% filter(name=="Rupert" , sex == "M")
plot(res$year,res$prop*100)
res <-babynames %>% filter(name=="Gordon" , sex == "M")
plot(res$year,res$prop*100)
res <-babynames %>% filter(name=="Donald" , sex == "M")
plot(res$year,res$prop*100)
res <-babynames %>% filter(year >= 1980)
View(res)
res <-babynames %>% filter(year >= 1980) %>% group_by(name,sex) %>% summarize(count = sum(n)) %>% group_by(sex)
View(res)
res <-babynames %>% filter(year >= 1980) %>% group_by(name,sex) %>% summarize(count = sum(n)) %>% group_by(sex) %>% mutate(rank = min_rank(desc(count))) %>% filter(rank < 10) M %>% arrange(sex,rank)
res <-babynames %>% filter(year >= 1980) %>% group_by(name,sex) %>% summarize(count = sum(n)) %>% group_by(sex) %>% mutate(rank = min_rank(desc(count))) %>% filter(rank < 10) %>% arrange(sex,rank)
View(res)
res <-babynames %>% filter(year >= 1980) %>% group_by(name,sex) %>% summarize(count = sum(n)) %>% group_by(sex) %>% mutate(rank = min_rank(desc(count))) %>% filter(rank < 10) %>% arrange(sex,rank) %>% select(name,sex,rank)
View(res)
topNames1986Yearly <- babynames %>%
inner_join(select(res, sex, name))
View(topNames_tbl)
View(topNames1986Yearly)
ggplot(topNames1986Yearly, aes(year, count, color=name)) +
facet_grid(~sex) +
geom_line() +
ggtitle("Most Popular Names of 1986")
ggplot(topNames1986Yearly, aes(year, count, color=name)) +
facet_grid(~sex) +
geom_line() +
ggtitle("Most Popular Names of 1986")
ggplot(topNames1986Yearly, aes(year, n, color=name)) +
facet_grid(~sex) +
geom_line() +
ggtitle("Most Popular Names of 1986")
res <-babynames %>% filter(year >= 1980) %>% group_by(name,sex) %>% summarize(count = sum(n)) %>% group_by(sex) %>% mutate(rank = min_rank(desc(count))) %>% filter(rank < 4) %>% arrange(sex,rank) %>% select(name,sex,rank)
topNames1986Yearly <- babynames %>%
inner_join(select(res, sex, name))
ggplot(topNames1986Yearly, aes(year, n, color=name)) +
facet_grid(~sex) +
geom_line() +
ggtitle("Most Popular Names of 1986")
ggplot(topNames1986Yearly, aes(year, prop, color=name)) +
facet_grid(~sex) +
geom_line() +
ggtitle("Most Popular Names of 1986")
plot(cars)
plot(cars)
plot(cars)
knit_with_parameters('~/Research/testpy.Rmd')
plot(cars)
plot(cars)
plot(cars)
plot(cars)
xdata = c(1 ,5, 10, 20, 100)
> ydata = c(23.83333333, 210.3666667, 545.3666667, 1756.866667, 38595.7)
xdata = c(1 ,5, 10, 20, 100)
ydata = c(23.83333333, 210.3666667, 545.3666667, 1756.866667, 38595.7)
library(ggplot2)
ggplot(dat,aes(x=xdata,y=ydata)) +
geom_point() +
geom_smooth(method="nls", formula=y ~ p1+p2*x^2, se=FALSE,
start=list(p1=p1,p2=p2))
install.packages(c("backports", "curl", "earth", "janeaustenr", "R.matlab", "RcppArmadillo", "reshape", "reshape2", "semTools", "texreg"))
plot(cars)
plot(cars)
setwd("~/Research/cvCells/macro-tests")
setwd("~/Research/cvCells/macro-tests/in-grey-seg")
library(EBImage)
sp.sec<-"all"
refs.all <-list.files(pattern = paste0("*-g-",sp.sec))
segs.all <-list.files(pattern = paste0("*-g-",sp.sec))
refs.all <-list.files(pattern = "*-g-")
segs.all <-list.files(pattern = "*-s-")
beg = 1
end = as.numeric(length(refs.all))
ref <-as.character(strsplit(refs.all,".tif"))
seg <-as.character(strsplit(segs.all,".tif"))
for (i in beg:end){
# read and label segmented images
refs.array <-readImage(refs.all[i])
seg.array <-readImage(segs.all[i])
seg.labelled <-bwlabel(seg.array)
# contruct holders for feature-results
writer.1 <-paste0("shapes",i)
writer.2 <-paste0("textures",i)
# compute features
fts.shp <-computeFeatures(seg.labelled,refs.array)
fts.tex <-computeFeatures.haralick(seg.labelled,refs.array)
# assigning source file ids to rownames for book-keeping
rownames(fts.shp) <-rep(ref[i],dim(fts.shp)[1])
# use assign for each feature set
assign(writer.1,fts.shp)
assign(writer.2,fts.tex)
}
rm(list=ls(pattern = "^fts"))
pieces.shp <-Filter(function(x) is(x, "matrix"),mget(ls(pattern = "^shapes")))
pieces.tex <-Filter(function(x) is(x, "matrix"), mget(ls(pattern= "^textures")))
data.shapes <-do.call(rbind,pieces.shp)
data.textures <-do.call(rbind,pieces.tex)
crt <-which(data.shapes[,6]>=7500) # size criteria here
data.shapes.trim <-data.shapes[crt,] # apply to shape data
data.textures.trim <-data.textures[crt,] # apply for textures
array.images <-cbind(data.shapes.trim,data.textures.trim)
library(stringr)
library(magrittr)
rm(list = ls(pattern = "^shapes"))
rm(list = ls(pattern = "^textures"))
array.dfs <-as.data.frame(array.images)
rNames <-rownames(array.dfs)
rNames.tag <-str_sub(rNames,-4)
array.dfs %<>% cbind(rNames.tag,.) # bind to array
save(array.dfs,file=paste0("array","-",sp.sec,".Rdata")) # export as .Rdata file
write.csv(array.dfs,file = paste0("array","-",sp.sec,".csv"),row.names = FALSE) # write out feature matrix to .csv
library(caret)
load("array-all.Rdata")
feats <- array.dfs[-1]
descrCor <- cor(feats)
View(array.dfs)
highlyCorDescr <- findCorrelation(descrCor, cutoff = .95)
filteredDescr <- feats[,-highlyCorDescr]
array.all.trim<-cbind(array.dfs[1],filteredDescr)
write.csv(array.all.trim,file = "array.all.trim.csv",row.names = FALSE) # write out feature matrix to .csv
rm(array.dfs,feats,descrCor,highlyCorDescr,filteredDescr,array.all.trim) #clean up
library(sparklyr) # first for linux: may have to move pre-process
sc <- spark_connect(master = "local") # connect to spark instance
library(dplyr)
features_tbl <- spark_read_csv(sc, name = 'featLib', path = '~/Research/cvCells/macro-tests/in-grey-seg/array.all.trim.csv')
rf_full_model <- features_tbl %>%
ml_random_forest(rNames_tag ~., type = "classification")
rf_full_predict <- sdf_predict(rf_full_model, features_tbl) %>%
ft_string_indexer("rNames_tag","rNames_idx") %>% collect
table(rf_full_predict$rNames_idx,rf_full_predict$prediction) # print the classification results
ft_string2idx <- features_tbl %>% # mapping of labels to indicies
ft_string_indexer("rNames_tag", "rNames_idx") %>%
ft_index_to_string("rNames_idx", "rNames_remap") %>%
collect
table(ft_string2idx$rNames_idx,ft_string2idx$rNames_remap) # show mapping
