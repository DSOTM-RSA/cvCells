group_by(country, continent)
View(by_country)
by_country <- gapminder %>%
group_by(country, continent) %>%
nest()
by_country
by_country$data[[1]]
country_model <- function(df) {
lm(lifeExp ~ year, data = df)
}
models <- map(by_country$data, country_model)
by_country <- by_country %>%
mutate(model = map(data, country_model))
by_country %>%
filter(continent == "Europe")
by_country %>%
arrange(continent, country)
by_country <- by_country %>%
mutate(
resids = map2(data, model, add_residuals)
)
resids <- unnest(by_country, resids)
resids
resids %>%
ggplot(aes(year, resid)) +
geom_line(aes(group = country), alpha = 1 / 3) +
geom_smooth(se = FALSE)
resids %>%
ggplot(aes(year, resid, group = country)) +
geom_line(alpha = 1 / 3) +
facet_wrap(~continent)
broom::glance(nz_mod)
by_country %>%
mutate(glance = map(model, broom::glance)) %>%
unnest(glance)
glance <- by_country %>%
mutate(glance = map(model, broom::glance)) %>%
unnest(glance, .drop = TRUE)
View(glance)
glance %>%
arrange(r.squared)
glance %>%
ggplot(aes(continent, r.squared)) +
geom_jitter(width = 0.5)
bad_fit <- filter(glance, r.squared < 0.25)
gapminder %>%
semi_join(bad_fit, by = "country") %>%
ggplot(aes(year, lifeExp, colour = country)) +
geom_line()
gapminder %>%
group_by(country, continent) %>%
nest()
gapminder %>%
nest(year:gdpPercap)
install.packages(c("globals", "h2o", "snow"))
if ("package:h2o" %in% search()) detach("package:h2o", unload=TRUE)
if ("h2o" %in% rownames(installed.packages())) remove.packages("h2o")
install.packages("h2o", type = "source",
repos = "http://h2o-release.s3.amazonaws.com/h2o/rel-turing/6/R")
library(sparklyr)
library(sparklyr)
library(rsparkling)
library(dplyr)
sc <- spark_connect("local", version = "1.6.2")
mtcars_tbl <- copy_to(sc, mtcars, "mtcars", overwrite = TRUE)
partitions <- mtcars_tbl %>%
filter(hp >= 100) %>%
mutate(cyl8 = cyl == 8) %>%
sdf_partition(training = 0.5, test = 0.5, seed = 1099)
training <- as_h2o_frame(sc, partitions$training)
test <- as_h2o_frame(sc, partitions$test)
glm_model <- h2o.glm(x = c("wt", "cyl"),
y = "mpg",
training_frame = training,
lambda_search = TRUE)
print(glm_model)
library(ggplot2)
# compute predicted values on our test dataset
pred <- h2o.predict(glm_model, newdata = test)
# convert from H2O Frame to Spark DataFrame
predicted <- as_spark_dataframe(sc, pred)
# extract the true 'mpg' values from our test dataset
actual <- partitions$test %>%
select(mpg) %>%
collect() %>%
`[[`("mpg")
# produce a data.frame housing our predicted + actual 'mpg' values
data <- data.frame(
predicted = predicted,
actual    = actual
)
# a bug in data.frame does not set colnames properly; reset here
names(data) <- c("predicted", "actual")
# plot predicted vs. actual values
ggplot(data, aes(x = actual, y = predicted)) +
geom_abline(lty = "dashed", col = "red") +
geom_point() +
theme(plot.title = element_text(hjust = 0.5)) +
coord_fixed(ratio = 1) +
labs(
x = "Actual Fuel Consumption",
y = "Predicted Fuel Consumption",
title = "Predicted vs. Actual Fuel Consumption"
)
iris_tbl <- copy_to(sc, iris, "iris", overwrite = TRUE)
iris_tbl
iris_hf <- as_h2o_frame(sc, iris_tbl)
kmeans_model <- h2o.kmeans(training_frame = iris_hf,
x = 3:4,
k = 3,
seed = 1)
h2o.centroid_stats(kmeans_model)
pca_model <- h2o.prcomp(training_frame = iris_hf,
x = 1:4,
k = 4,
seed = 1)
print(pca_model)
y <- "Species"
x <- setdiff(names(iris_hf), y)
iris_hf[,y] <- as.factor(iris_hf[,y])
splits <- h2o.splitFrame(iris_hf, seed = 1)
rf_model <- h2o.randomForest(x = x,
y = y,
training_frame = splits[[1]],
validation_frame = splits[[2]],
nbins = 32,
max_depth = 5,
ntrees = 20,
seed = 1)
h2o.confusionMatrix(rf_model, valid = TRUE)
h2o.varimp_plot(rf_model)
gbm_model <- h2o.gbm(x = x,
y = y,
training_frame = splits[[1]],
validation_frame = splits[[2]],
ntrees = 20,
max_depth = 3,
learn_rate = 0.01,
col_sample_rate = 0.7,
seed = 1)
h2o.confusionMatrix(gbm_model, valid = TRUE)
path <- system.file("extdata", "prostate.csv", package = "h2o")
prostate_df <- spark_read_csv(sc, "prostate", path)
head(prostate_df)
prostate_hf <- as_h2o_frame(sc, prostate_df)
splits <- h2o.splitFrame(prostate_hf, seed = 1)
y <- "VOL"
x <- setdiff(names(prostate_hf), c("ID", y))
dl_fit <- h2o.deeplearning(x = x, y = y,
training_frame = splits[[1]],
epochs = 15,
activation = "Rectifier",
hidden = c(10, 5, 10),
input_dropout_ratio = 0.7)
h2o.performance(dl_fit, newdata = splits[[2]])
splits <- h2o.splitFrame(prostate_hf, seed = 1)
y <- "VOL"
#remove response and ID cols
x <- setdiff(names(prostate_hf), c("ID", y))
# GBM hyperparamters
gbm_params1 <- list(learn_rate = c(0.01, 0.1),
max_depth = c(3, 5, 9),
sample_rate = c(0.8, 1.0),
col_sample_rate = c(0.2, 0.5, 1.0))
# Train and validate a grid of GBMs
gbm_grid1 <- h2o.grid("gbm", x = x, y = y,
grid_id = "gbm_grid1",
training_frame = splits[[1]],
validation_frame = splits[[1]],
ntrees = 100,
seed = 1,
hyper_params = gbm_params1)
gbm_gridperf1 <- h2o.getGrid(grid_id = "gbm_grid1",
sort_by = "mse",
decreasing = FALSE)
print(gbm_gridperf1)
gbm_params2 <- list(learn_rate = seq(0.01, 0.1, 0.01),
max_depth = seq(2, 10, 1),
sample_rate = seq(0.5, 1.0, 0.1),
col_sample_rate = seq(0.1, 1.0, 0.1))
search_criteria2 <- list(strategy = "RandomDiscrete",
max_models = 150)
# Train and validate a grid of GBMs
gbm_grid2 <- h2o.grid("gbm", x = x, y = y,
grid_id = "gbm_grid2",
training_frame = splits[[1]],
validation_frame = splits[[2]],
ntrees = 100,
seed = 1,
hyper_params = gbm_params2,
search_criteria = search_criteria2)
gbm_gridperf2 <- h2o.getGrid(grid_id = "gbm_grid2",
sort_by = "mse",
decreasing = FALSE)
gbm_gridperf2@summary_table[1,]
install.packages("rbokeh")
library(sparklyr)
library(dplyr)
library(babynames)
library(ggplot2)
library(dygraphs)
library(rbokeh)
install.packages("dygraphs")
sc <- spark_connect(master = "local")
babynames_tbl <- copy_to(sc, babynames, "babynames")
applicants_tbl <- copy_to(sc, applicants, "applicants")
birthsYearly <- applicants_tbl %>% mutate(male = ifelse(sex=="M",n_all,0), female=ifelse(sex== "F",n_all,0))
birthsYearly <- applicants_tbl %>% mutate(male = ifelse(sex=="M",n_all,0), female=ifelse(sex== "F",n_all,0)) %>% group_by(year) %>% summarize(Male=sum(male)/ 1000000, Female = sum(female) / 1000000) %>% arrange(year) %>% collect
birthsYearly <- applicants_tbl %>% mutate(male = ifelse(sex=="M",n_all,0), female=ifelse(sex== "F",n_all,0)) %>% collect()
View(birthsYearly)
birthsYearly <- applicants_tbl %>% mutate(male = ifelse(sex=="M",n_all,0), female=ifelse(sex== "F",n_all,0)) %>% group_by(year) %>% summarize(Male=sum(male)/ 1000000, Female = sum(female) / 1000000) %>% arrange(year) %>% collect
View(birthsYearly)
birthsYearly %>%
dygraph(main = "Total US Births (SSN)", ylab = "Millions") %>%
dySeries("Female") %>%
dySeries("Male") %>%
dyOptions(stackedGraph = TRUE) %>%
dyRangeSelector(height = 20)
install.packages("dygraphs")
library(dygraphs)
birthsYearly %>%
dygraph(main = "Total US Births (SSN)", ylab = "Millions") %>%
dySeries("Female") %>%
dySeries("Male") %>%
dyOptions(stackedGraph = TRUE) %>%
dyRangeSelector(height = 20)
topNames_tbl <- babynames_tbl %>% filter(year >=1986) %>% group_by(name,sex) %>% summarize(count =as.numeric(sum(n)))
topNames_tbl <- babynames_tbl %>% filter(year >=1986) %>% group_by(name,sex) %>% summarize(count =as.numeric(sum(n))) %>% collect()
View(topNames_tbl)
View(birthsYearly)
topNames_tbl <- babynames_tbl %>%
filter(year >= 1986) %>%
group_by(name, sex) %>%
summarize(count = as.numeric(sum(n))) %>%
filter(count > 1000) %>%
select(name, sex) %>% collect()
View(topNames_tbl)
filteredNames_tbl <- babynames_tbl %>%
filter(year >= 1986) %>%
inner_join(topNames_tbl) %>% collect()
filteredNames_tbl <- babynames_tbl %>%
filter(year >= 1986) %>%
inner_join(topNames_tbl)
topNames_tbl <- babynames_tbl %>%
filter(year >= 1986) %>%
group_by(name, sex) %>%
summarize(count = as.numeric(sum(n))) %>%
filter(count > 1000) %>%
select(name, sex)
filteredNames_tbl <- babynames_tbl %>%
filter(year >= 1986) %>%
inner_join(topNames_tbl)
filteredNames_tbl <- babynames_tbl %>%
filter(year >= 1986) %>%
inner_join(topNames_tbl) %>% collect()
filteredNames_tbl <- babynames_tbl %>%
filter(year >= 1986) %>%
inner_join(topNames_tbl)
yearlyNames_tbl <- filteredNames_tbl %>%
group_by(year, name, sex) %>%
summarize(count = as.numeric(sum(n)))
sdf_register(yearlyNames_tbl, "yearlyNames")
topNames_tbl <- babynames_tbl %>%
filter(year >= 1986) %>%
group_by(name, sex) %>%
summarize(count = as.numeric(sum(n)))
topNames_tbl <- babynames_tbl %>%
filter(year >= 1986) %>%
group_by(name, sex) %>%
summarize(count = as.numeric(sum(n))) %>% collect()
View(topNames_tbl)
View(birthsYearly)
View(birthsYearly)
data("babynames")
data("babynames")
View(babynames)
res <-babynames %>% filter(name=="Mary")
View(res)
res <-babynames %>% filter(name=="Mary" | sex == "M")
View(res)
res <-babynames %>% filter(name=="Mary" , sex == "M")
View(res)
res <-babynames %>% filter(name=="Mary" , sex == "F")
View(res)
plot(res$year,res$prop)
plot(res$year,res$prop*100)
res <-babynames %>% filter(name=="Beyonce" , sex == "F")
plot(res$year,res$prop*100)
res <-babynames %>% filter(name=="Salvador" , sex == "M")
plot(res$year,res$prop*100)
res <-babynames %>% filter(name=="Daniel" , sex == "M")
plot(res$year,res$prop*100)
res <-babynames %>% filter(name=="George" , sex == "M")
plot(res$year,res$prop*100)
res <-babynames %>% filter(name=="John" , sex == "M")
plot(res$year,res$prop*100)
res <-babynames %>% filter(name=="Paul" , sex == "M")
plot(res$year,res$prop*100)
res <-babynames %>% filter(name=="Jennifer" , sex == "F")
plot(res$year,res$prop*100)
res <-babynames %>% filter(name=="Audrey" , sex == "F")
plot(res$year,res$prop*100)
res <-babynames %>% filter(name=="Marilyn" , sex == "F")
plot(res$year,res$prop*100)
res <-babynames %>% filter(name=="Elvis" , sex == "M")
plot(res$year,res$prop*100)
res <-babynames %>% filter(name=="Michael" , sex == "M")
plot(res$year,res$prop*100)
res <-babynames %>% filter(name=="Rupert" , sex == "M")
plot(res$year,res$prop*100)
res <-babynames %>% filter(name=="Gordon" , sex == "M")
plot(res$year,res$prop*100)
res <-babynames %>% filter(name=="Donald" , sex == "M")
plot(res$year,res$prop*100)
res <-babynames %>% filter(year >= 1980)
View(res)
res <-babynames %>% filter(year >= 1980) %>% group_by(name,sex) %>% summarize(count = sum(n)) %>% group_by(sex)
View(res)
res <-babynames %>% filter(year >= 1980) %>% group_by(name,sex) %>% summarize(count = sum(n)) %>% group_by(sex) %>% mutate(rank = min_rank(desc(count))) %>% filter(rank < 10) M %>% arrange(sex,rank)
res <-babynames %>% filter(year >= 1980) %>% group_by(name,sex) %>% summarize(count = sum(n)) %>% group_by(sex) %>% mutate(rank = min_rank(desc(count))) %>% filter(rank < 10) %>% arrange(sex,rank)
View(res)
res <-babynames %>% filter(year >= 1980) %>% group_by(name,sex) %>% summarize(count = sum(n)) %>% group_by(sex) %>% mutate(rank = min_rank(desc(count))) %>% filter(rank < 10) %>% arrange(sex,rank) %>% select(name,sex,rank)
View(res)
topNames1986Yearly <- babynames %>%
inner_join(select(res, sex, name))
View(topNames_tbl)
View(topNames1986Yearly)
ggplot(topNames1986Yearly, aes(year, count, color=name)) +
facet_grid(~sex) +
geom_line() +
ggtitle("Most Popular Names of 1986")
ggplot(topNames1986Yearly, aes(year, count, color=name)) +
facet_grid(~sex) +
geom_line() +
ggtitle("Most Popular Names of 1986")
ggplot(topNames1986Yearly, aes(year, n, color=name)) +
facet_grid(~sex) +
geom_line() +
ggtitle("Most Popular Names of 1986")
res <-babynames %>% filter(year >= 1980) %>% group_by(name,sex) %>% summarize(count = sum(n)) %>% group_by(sex) %>% mutate(rank = min_rank(desc(count))) %>% filter(rank < 4) %>% arrange(sex,rank) %>% select(name,sex,rank)
topNames1986Yearly <- babynames %>%
inner_join(select(res, sex, name))
ggplot(topNames1986Yearly, aes(year, n, color=name)) +
facet_grid(~sex) +
geom_line() +
ggtitle("Most Popular Names of 1986")
ggplot(topNames1986Yearly, aes(year, prop, color=name)) +
facet_grid(~sex) +
geom_line() +
ggtitle("Most Popular Names of 1986")
plot(cars)
plot(cars)
plot(cars)
knit_with_parameters('~/Research/testpy.Rmd')
plot(cars)
plot(cars)
plot(cars)
plot(cars)
xdata = c(1 ,5, 10, 20, 100)
> ydata = c(23.83333333, 210.3666667, 545.3666667, 1756.866667, 38595.7)
xdata = c(1 ,5, 10, 20, 100)
ydata = c(23.83333333, 210.3666667, 545.3666667, 1756.866667, 38595.7)
library(ggplot2)
ggplot(dat,aes(x=xdata,y=ydata)) +
geom_point() +
geom_smooth(method="nls", formula=y ~ p1+p2*x^2, se=FALSE,
start=list(p1=p1,p2=p2))
install.packages(c("backports", "curl", "earth", "janeaustenr", "R.matlab", "RcppArmadillo", "reshape", "reshape2", "semTools", "texreg"))
plot(cars)
plot(cars)
install.packages(c("enpls", "janeaustenr", "lava", "MCMCpack", "Rcmdr", "stochvol"))
library(purrr)
library(magrittr)
test.matrix <- matrix(1:6, nrow=2, ncol = 3,
dimnames = list(c('r1', 'r2'),
c('c1', 'c2', 'c3')))
list('a' = test.matrix) %>% map(function(x){x['r2', 'c1']})
View(test.matrix)
list('a' = test.matrix) %>% map(function(x){x[1, 2]})
list('a' = test.matrix) %>% map(function(x){x[1:2, 2]})
list('a' = test.matrix) %>% map(function(x){x[1:2, ]})
library(plyr)
library(dplyr)
library(purrr)
library(tidyr)
library(ggplot2)
dataTable <- read.table("data/MAP_dat.tsv",header=T) # read in count data
library(purrr)
sampled_dt <- dataTable %>% group_by(depth) %>% nest() %>% mutate(n=2) %>% # example of using purrr for sampling
mutate(samp=map2(data,n,sample_n,replace=TRUE)) %>% select(depth,samp) %>% unnest()
View(sampled_dt)
mat_dt <- dataTable %>% group_by(depth) %>% nest()
View(mat_dt)
mat_dt <- dataTable %>% group_by(depth) %>% nest() %>% map(function(x){x[1:2, ]})
mat_dt <- dataTable %>% group_by(depth) %>% nest() %>% map(.,function(x){x[1:2, ]})
mat_dt <- dataTable %>% group_by(depth) %>% nest() %>% map(function(x){x[1:2, ]})
mat_dt <- dataTable %>% group_by(depth) %>% nest()
dataTable %>% group_by(depth) %>% nest() %>% list('a'=.$data)
dataTable %>% group_by(depth) %>% nest() %>% list('a'=.$data) %>%  map(function(x){x[1:2, ]})
dataTable %>% group_by(depth) %>% nest() %>% list('a'=.$data) %>%  map(function(x){x[, ]})
dataTable %>% group_by(depth) %>% nest() %>% list('a'=.$data) %>%  map(function(x){x[ ]})
dataTable %>% group_by(depth) %>% nest() %>% list('a'=.$data) %>%  map(function(x){x[][1:2,]})
dataTable %>% group_by(depth)
dataTable %>% group_by(depth) %>% .[1:2,]
dataTable %>% group_by(depth) %>% .[,5:10]
out<-dataTable %>% group_by(depth) %>% .[,6:10]
str(out)
out<-dataTable %>% group_by(depth) %>% .[,6:10] %>% as.matrix()
View(out)
out<-dataTable %>% group_by(depth) %>% .[,6:10] %>% as.matrix() %>% nest()
out<-dataTable %>% group_by(depth) %>% .[,6:10] %>% as.matrix() %>% dist()
str(out)
library(sparklyr)
library(rsparkling)
library(dplyr)
sc <- spark_connect("local", version = "1.6.2")
mtcars_tbl <- copy_to(sc, mtcars, "mtcars", overwrite = TRUE)
partitions <- mtcars_tbl %>%
filter(hp >= 100) %>%
mutate(cyl8 = cyl == 8) %>%
sdf_partition(training = 0.5, test = 0.5, seed = 1099)
training <- as_h2o_frame(sc, partitions$training)
test <- as_h2o_frame(sc, partitions$test)
partitions2 <- h2o.splitFrame(as_h2o_frame(mtcars_tbl), 0.5))
partitions2 <- h2o.splitFrame(as_h2o_frame(mtcars_tbl), 0.5)
glm_model <- h2o.glm(x = c("wt", "cyl"),
y = "mpg",
training_frame = training,
lambda_search = TRUE)
training <- as_h2o_frame(sc, mtcars_tbl)
setwd("~/Research/cvCells/macro-tests")
setwd("~/Research/cvCells/macro-tests/in-grey-seg")
library(sparklyr) # first for linux: may have to move pre-process
library(rsparkling)
library(dplyr)
sc <- spark_connect(master = "local")
features_tbl <- spark_read_csv(sc, name = 'featLib', path = '~/Research/cvCells/macro-tests/in-grey-seg/array.all.trim.csv')
str(features_tbl)
training <- as_h2o_frame(sc, features_tbl)
partitions <- features_tbl %>%
sdf_partition(training = 0.75, test = 0.5, seed = 1099)
training <- as_h2o_frame(sc, partitions$training)
test <- as_h2o_frame(sc, partitions$test)
kmeans_model <- h2o.kmeans(training_frame = training,
x = 2:31,
k = 3,
seed = 1)
h2o.centers(kmeans_model)
h2o.centroid_stats(kmeans_model)
pca_model <- h2o.prcomp(training_frame = training,
x = 2:31,
k = 4,
seed = 1)
print(pca_model)
dat.H2o.train <- as_h2o_frame(sc, features_tbl)
y <- "rNames_tag"
x <- setdiff(names(dat.H2o.train), y)
dat.H2o.train[,y] <- as.factor(dat.H2o.train[,y])
splits <- h2o.splitFrame(dat.H2o.train, seed = 1)
rf_model <- h2o.randomForest(x = x,
y = y,
training_frame = splits[[1]],
validation_frame = splits[[2]],
nbins = 32,
max_depth = 5,
ntrees = 20,
seed = 1)
h2o.confusionMatrix(rf_model, valid = TRUE)
h2o.varimp_plot(rf_model)
gbm_model <- h2o.gbm(x = x,
y = y,
training_frame = splits[[1]],
validation_frame = splits[[2]],
ntrees = 20,
max_depth = 3,
learn_rate = 0.01,
col_sample_rate = 0.7,
seed = 1)
h2o.confusionMatrix(gbm_model, valid = TRUE)
h2o.confusionMatrix(gbm_model)
gbm_model <- h2o.gbm(x = x,
y = y,
training_frame = splits[[1]],
validation_frame = splits[[2]],
ntrees = 20,
max_depth = 3,
learn_rate = 0.01,
col_sample_rate = 0.7,
seed = 1)
h2o.confusionMatrix(gbm_model, valid = TRUE)
h2o.confusionMatrix(gbm_model, valid = TRUE)
h2o.confusionMatrix(gbm_model)
a<-h2o.confusionMatrix(gbm_model)
View(a)
rf_model <- h2o.randomForest(x = x,
y = y,
training_frame = splits[[1]],
validation_frame = splits[[2]],
nbins = 32,
max_depth = 5,
ntrees = 20,
seed = 1)
h2o.confusionMatrix(rf_model, valid = TRUE)
str(a)
dl_fit <- h2o.deeplearning(x = x, y = y,
training_frame = splits[[1]],
epochs = 15,
activation = "Rectifier",
hidden = c(21, 5, 21),
input_dropout_ratio = 0.7)
h2o.performance(dl_fit, newdata = splits[[2]])
h2o.performance(dl_fit)
